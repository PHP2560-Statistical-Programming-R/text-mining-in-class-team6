word_counts_all %>%
# Take the top 5 words for each sentiment
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
# Set up the plot with aes()
ggplot(aes(word, n, mapping = sentiment)) +
geom_col(show.legend = FALSE, width = 0.5) +
facet_wrap(~ sentiment, scales = "free", nrow = 5) +
coord_flip() +
ggtitle("Top 5 words for each sentiment") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/top10_pos_and_neg.png')
word_counts_pos_neg %>%
# Group by sentiment
group_by(sentiment) %>%
# Take the top 10 for each sentiment
top_n(10) %>%
ungroup() %>%
# Make word a factor in order of n
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
# Make a bar chart with geom_col()
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
coord_flip() +
ggtitle("Top 10 positive & negative words") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/change_over_time.png')
sentiment_by_time %>%
# Filter for positive and negative words
filter(sentiment %in% c("positive", "negative")) %>%
# Count by date, sentiment, and total_words
count(time, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n / total_words) %>%
# Set up the plot with aes()
ggplot(aes(time, percent, mapping = sentiment)) +
geom_line(aes(colour = sentiment, group = sentiment), size = 1) +
geom_smooth(method = "lm", se = FALSE, lty = 2) +
expand_limits(y = 0) +
ggtitle("Sentiment change over time") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
names <- c(
"dplyr",
"stringr",
"rebus",
"lubridate",
"ggplot2",
"tidytext",
"wordcloud"
)
for(name in names) {
if (!(name %in% installed.packages()))
install.packages(name, repos="http://cran.us.r-project.org")
library(name, character.only=TRUE)
}
# export the data manually from "http://www.trumptwitterarchive.com/archive" and save as a csv file
# read the csv file
DT_all_tweets <- read.csv("data/Donald_Trump_twitter.csv")
# get the date and the time of the most recent tweet
most_recent_tweet <- DT_all_tweets[1, 3]
# print the date and the time of the most recent tweet
paste0("The date and the time of the most recent tweet: ", most_recent_tweet)
date_and_time <- DT_all_tweets$created_at %>%
str_split(pattern = " ", simplify = TRUE) %>%
as_tibble() %>%
rename(date = V1, time = V2) %>%
mutate(date = as.Date(date, "%m/%d/%y"))
date <- date_and_time$date %>%
str_match(
pattern = capture(one_or_more(DGT)) %R%
"-" %R% capture(one_or_more(DGT)) %R%
"-" %R% capture(one_or_more(DGT))
) %>%
as_tibble() %>%
rename(date = V1, year = V2, month = V3, day = V4)
clean_data <- DT_all_tweets %>%
cbind(date) %>%
filter(is_retweet == "FALSE") %>%
select(text, date, year, month, day)
clean_data$text <- as.character(clean_data$text)
tidy_words <- clean_data %>%
as.tbl() %>%
unnest_tokens(word, text) %>%
filter(!(word %in% c(
"t.co",
"http",
"https",
"amp",
"twitter",
"android",
"web",
"client",
"realdonaldtrump"
)))
word_counts_all <- tidy_words %>%
# Implement sentiment analysis using the "nrc" lexicon
inner_join(get_sentiments("nrc")) %>%
# Count by word and sentiment
count(word, sentiment) %>%
# Group by sentiment
group_by(sentiment)
word_counts_pos_neg <- tidy_words %>%
# Implement sentiment analysis using the "nrc" lexicon
inner_join(get_sentiments("nrc")) %>%
filter(sentiment %in% c("positive", "negative")) %>%
# Count by word and sentiment
count(word, sentiment)
sentiment_by_time <- tidy_words %>%
# Define a new column using floor_date()
mutate(time = floor_date(as_datetime(date), unit = "6 months")) %>%
# Group by date
group_by(time) %>%
mutate(total_words = n()) %>%
ungroup() %>%
# Implement sentiment analysis using the NRC lexicon
inner_join(get_sentiments("nrc"))
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2015)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
dir.create("graph/", showWarnings = FALSE)
png('graph/top10.png')
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
top_n(10) %>%
ggplot(aes(word, n, fill = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Top 10 expressions") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/wordcloud.png')
par(mfrow = c(2,2))
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2017)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y= 0, "2017")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2016)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2"), main = "P"))
text(x=0.5, y=0, "2016")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2015)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2015")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2014)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2014")
dev.off()
png('graph/top5_sentiments.png')
word_counts_all %>%
# Take the top 5 words for each sentiment
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
# Set up the plot with aes()
ggplot(aes(word, n, mapping = sentiment)) +
geom_col(show.legend = FALSE, width = 0.5) +
facet_wrap(~ sentiment, scales = "free", nrow = 5) +
coord_flip() +
ggtitle("Top 5 words for each sentiment") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/top10_pos_and_neg.png')
word_counts_pos_neg %>%
# Group by sentiment
group_by(sentiment) %>%
# Take the top 10 for each sentiment
top_n(10) %>%
ungroup() %>%
# Make word a factor in order of n
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
# Make a bar chart with geom_col()
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
coord_flip() +
ggtitle("Top 10 positive & negative words") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/change_over_time.png')
sentiment_by_time %>%
# Filter for positive and negative words
filter(sentiment %in% c("positive", "negative")) %>%
# Count by date, sentiment, and total_words
count(time, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n / total_words) %>%
# Set up the plot with aes()
ggplot(aes(time, percent, mapping = sentiment)) +
geom_line(aes(colour = sentiment, group = sentiment), size = 1) +
geom_smooth(method = "lm", se = FALSE, lty = 2) +
expand_limits(y = 0) +
ggtitle("Sentiment change over time") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
remove.packages("lubridate", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
names <- c(
"dplyr",
"stringr",
"rebus",
"lubridate",
"ggplot2",
"tidytext",
"wordcloud"
)
for(name in names) {
if (!(name %in% installed.packages()))
install.packages(name, repos="http://cran.us.r-project.org")
library(name, character.only=TRUE)
}
install.packages(name, repos = "http://cran.us.r-project.org")
## clean all output from previous runs of scripts
unlink("graph", recursive = TRUE) # where graphs are stores
# now re-create the results directory
dir.create(file.path("graph"), showWarnings = FALSE)
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
install.packages(name, repos = "http://cran.us.r-project.org")
## clean all output from previous runs of scripts
unlink("graph", recursive = TRUE) # where graphs are stores
# now re-create the results directory
dir.create(file.path("graph"), showWarnings = FALSE)
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
dir.create("graph/", showWarnings = FALSE)
png('graph/top10.png')
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
top_n(10) %>%
ggplot(aes(word, n, fill = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Top 10 expressions") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/wordcloud.png')
par(mfrow = c(2,2))
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2017)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y= 0, "2017")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2016)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2"), main = "P"))
text(x=0.5, y=0, "2016")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2015)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2015")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2014)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2014")
dev.off()
png('graph/top5_sentiments.png')
word_counts_all %>%
# Take the top 5 words for each sentiment
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
# Set up the plot with aes()
ggplot(aes(word, n, mapping = sentiment)) +
geom_col(show.legend = FALSE, width = 0.5) +
facet_wrap(~ sentiment, scales = "free", nrow = 5) +
coord_flip() +
ggtitle("Top 5 words for each sentiment") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/top10_pos_and_neg.png')
word_counts_pos_neg %>%
# Group by sentiment
group_by(sentiment) %>%
# Take the top 10 for each sentiment
top_n(10) %>%
ungroup() %>%
# Make word a factor in order of n
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
# Make a bar chart with geom_col()
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
coord_flip() +
ggtitle("Top 10 positive & negative words") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/change_over_time.png')
sentiment_by_time %>%
# Filter for positive and negative words
filter(sentiment %in% c("positive", "negative")) %>%
# Count by date, sentiment, and total_words
count(time, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n / total_words) %>%
# Set up the plot with aes()
ggplot(aes(time, percent, mapping = sentiment)) +
geom_line(aes(colour = sentiment, group = sentiment), size = 1) +
geom_smooth(method = "lm", se = FALSE, lty = 2) +
expand_limits(y = 0) +
ggtitle("Sentiment change over time") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
install.packages("lubridate", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
remove.packages("dplyr", lib="~/Library/R/3.3/library")
remove.packages("stringr", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
remove.packages("wordcloud", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
## clean all output from previous runs of scripts
unlink("graph", recursive = TRUE) # where graphs are stores
# now re-create the results directory
dir.create(file.path("graph"), showWarnings = FALSE)
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
## clean all output from previous runs of scripts
unlink("graph", recursive = TRUE) # where graphs are stores
# now re-create the results directory
dir.create(file.path("graph"), showWarnings = FALSE)
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
## clean all output from previous runs of scripts
unlink("graph", recursive = TRUE) # where graphs are stores
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
source("00_getting_packages.R")       # install and prepare the requiered packages
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
source("04_visualization.R")          # create plot and graphs
dir.create("graph/", showWarnings = FALSE)
png('graph/top10.png')
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
top_n(10) %>%
ggplot(aes(word, n, fill = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Top 10 expressions") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/wordcloud.png')
par(mfrow = c(2,2))
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2017)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y= 0, "2017")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2016)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2"), main = "P"))
text(x=0.5, y=0, "2016")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2015)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2015")
tidy_words %>%
anti_join(stop_words) %>%
filter(year == 2014)  %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
with(wordcloud(word, scale = c(1.5, .2), n, max.words = 100, random.order = F, random.color = F, colors = brewer.pal(8, "Dark2")))
text(x=0.5, y=0.2, "2014")
dev.off()
png('graph/top5_sentiments.png')
word_counts_all %>%
# Take the top 5 words for each sentiment
top_n(5) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
# Set up the plot with aes()
ggplot(aes(word, n, mapping = sentiment)) +
geom_col(show.legend = FALSE, width = 0.5) +
facet_wrap(~ sentiment, scales = "free", nrow = 5) +
coord_flip() +
ggtitle("Top 5 words for each sentiment") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/top10_pos_and_neg.png')
word_counts_pos_neg %>%
# Group by sentiment
group_by(sentiment) %>%
# Take the top 10 for each sentiment
top_n(10) %>%
ungroup() %>%
# Make word a factor in order of n
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
# Make a bar chart with geom_col()
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free") +
coord_flip() +
ggtitle("Top 10 positive & negative words") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
png('graph/change_over_time.png')
sentiment_by_time %>%
# Filter for positive and negative words
filter(sentiment %in% c("positive", "negative")) %>%
# Count by date, sentiment, and total_words
count(time, sentiment, total_words) %>%
ungroup() %>%
mutate(percent = n / total_words) %>%
# Set up the plot with aes()
ggplot(aes(time, percent, mapping = sentiment)) +
geom_line(aes(colour = sentiment, group = sentiment), size = 1) +
geom_smooth(method = "lm", se = FALSE, lty = 2) +
expand_limits(y = 0) +
ggtitle("Sentiment change over time") +
theme(plot.title = element_text(hjust = 0.5))
dev.off()
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
## run all scripts
source("00_getting_packages.R")       # install and prepare the requiered packages
source("01_getting_data.R")           # read and store the data
source("02_cleaning.R")               # clean the data
source("03_sentiment_analysis.R")     # conduct sentiment analysis
source("04_visualization.R")          # create plot and graphs
# rmarkdown::render("paper.Rmd", output_format = "html_document")
dir.create("graph/", showWarnings = FALSE)
png('graph/top10.png')
tidy_words %>%
anti_join(stop_words) %>%
count(word, sort = T) %>%
mutate(word = reorder(word, n)) %>%
top_n(10) %>%
ggplot(aes(word, n, fill = n)) +
geom_col() +
xlab(NULL) +
coord_flip() +
ggtitle("Top 10 expressions") +
theme(plot.title = element_text(hjust = 0.5))
source("04_visualization.R")          # create plot and graphs
