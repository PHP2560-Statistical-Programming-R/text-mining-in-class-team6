str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*" optional(" "), replacement = "") %>%
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "") %>%
str_split(pattern = fixed(" "))
head(split_words)
trump_clean[ , 2]
trump_clean[ , 2] %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "")
split_words <- trump_clean[ , 2] %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.{14}", replacement = "") %>%
str_split(pattern = fixed(" "))
head(split_words)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
str_split(pattern = fixed(" "))
trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
str_replace_all(pattern = START %R% "[[:punct:]]" %R% END, replacement = "")
trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
str_replace_all(pattern = "[[:punct:]]", replacement = "")
clean_split_words <- unlist(split_words)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
clean_split_words <- unlist(split_words)
head(clean_split_words)
clean_split_words
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist()
split_words
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.{14}", replacement = "") %>%
head(split_words)
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "") %>%
head(split_words)
trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist()
trump_clean[ , 2] %>%
str_split(pattern = fixed(" "))
trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist()
trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "")
trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "") %>%
head(split_words)
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
head(split_words)
trump <- read.csv("Trump.csv")
library(dplyr)
trump_clean <- trump %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
head(split_words)
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
split_words
trump <- read.csv("Trump.csv")
library(dplyr)
trump_clean <- trump %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
split_words <- trump_clean[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
split_words
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_trump %>%
filter(is_retweet == "FALSE")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "[[:punct:]]", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
clean_words_df <- clean_words %>%
count(sort = T)
table(clean_words)
clean_words_df <- data_frame(words = clean_words)
View(clean_words_df)
clean_words_df <- data_frame(words = clean_words)
clean_words_df %>% count(words, sort = T)
clean_words_df <- data_frame(words = clean_words) %>%
filter(words == "")
clean_words_df %>% count(words, sort = T)
clean_words_df <- data_frame(words = clean_words) %>%
filter(!words == "")
clean_words_df %>% count(words, sort = T)
clean_words_df <- data_frame(words = clean_words) %>%
filter(!(words == ""))
clean_words_df %>% count(words, sort = T)
clean_words_df <- data_frame(words = clean_words) %>%
filter(!(words == ""))
word_count <- clean_words_df %>%
count(words, sort = T)
View(word_count)
library(ggplot2)
ggplot(word_count, aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(head(word_count), aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(top_n(word_count), aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(word_count[10, ], aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(word_count[1:10, ], aes(words, n)) +
geom_point()
View(word_count)
View(clean_words_df)
View(word_count)
View(word_count)
View(word_count)
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "\\W", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "\\W", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
clean_words_df <- data_frame(words = clean_words) %>%
filter(!(words == ""))
word_count <- clean_words_df %>%
count(words, sort = T)
library(ggplot2)
ggplot(word_count[1:10, ], aes(words, n)) +
geom_point()
View(word_count)
View(word_count)
View(word_count)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
games <- read.csv("data/GAMES.csv")
# plot using log(attendance) with local regression (LOESS Curve fitting/LOESS smoothing)
ggplot(games, aes(x = log(Attendance) , y= Total_Score)) +
geom_point(size=0.5) +
geom_smooth(size=0.7)
# log linear model and its summary
loglinearfit <- glm(Total_Score ~ log(Attendance), family = poisson(link = "log"), games)
summary(loglinearfit)
names
names(loglinearfit)
getwd()
setwd("/Users/Ozan/Desktop/")
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "\\W", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
clean_words_df <- data_frame(words = clean_words) %>%
filter(!(words == ""))
word_count <- clean_words_df %>%
count(words, sort = T)
library(ggplot2)
ggplot(word_count[1:10, ], aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(word_count[1:20, ], aes(words, n)) +
geom_point()
library(tidytext)
install.packages("tidytext", lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
library(tidytext)
trump_sentiment_nrc <- word_count %>%
inner_join(get_sentiments("nrc"))
View(word_count)
head(get_sentiments("nrc"))
all_tweets <- read.csv("Trump.csv")
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "\\W", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
clean_words_df <- data_frame(word = clean_words) %>%
filter(!(word == ""))
word_count <- clean_words_df %>%
count(word, sort = T)
library(ggplot2)
ggplot(word_count[1:20, ], aes(words, n)) +
geom_point()
library(ggplot2)
ggplot(word_count[1:20, ], aes(word, n)) +
geom_point()
library(tidytext)
trump_sentiment_nrc <- word_count %>%
inner_join(get_sentiments("nrc"))
View(trump_sentiment_nrc)
trump_sentiment_bing <- word_count %>%
inner_join(get_sentiments("bing"))
trump_sentiment_afinn <- word_count %>%
inner_join(get_sentiments("afinn"))
View(trump_sentiment_afinn)
View(trump_sentiment_nrc)
View(trump_sentiment_bing)
nrc <- trump_sentiment_nrc  %>%
filter(sentiment = "positive")
nrc <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
View(nrc)
library(tidytext)
nrc_positive <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
nrc_positive %>%
top_n(20) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
nrc_positive %>%
top_n(20)
nrc_positive %>%
top_n(10)
bing_positive <- trump_sentiment_bing  %>%
filter(sentiment == "positive")
bing_positive %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
library(tidytext)
nrc_positive <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
nrc_positive %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
library(tidytext)
nrc_positive <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
nrc_positive[1:10, ] %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
library(tidytext)
nrc_positive <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
nrc_positive %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
?top_n()
all_tweets <- read.csv("Trump.csv")
library(dplyr)
only_trump_tweets <- all_tweets %>%
filter(is_retweet == "FALSE")
library(stringr)
library(rebus)
clean_words <- only_trump_tweets[ , 2] %>%
str_split(pattern = fixed(" ")) %>%
unlist() %>%
str_replace_all(pattern = "\\W", replacement = "") %>%
str_replace_all(pattern = "http.*", replacement = "")
clean_words_df <- data_frame(word = clean_words) %>%
filter(!(word == ""))
word_count <- clean_words_df %>%
count(word, sort = T)
library(ggplot2)
ggplot(word_count[1:20, ], aes(word, n)) +
geom_point()
library(tidytext)
trump_sentiment_nrc <- word_count %>%
inner_join(get_sentiments("nrc"))
trump_sentiment_bing <- word_count %>%
inner_join(get_sentiments("bing"))
trump_sentiment_afinn <- word_count %>%
inner_join(get_sentiments("afinn"))
ggplot(word_count[1:20, ], aes(words, n)) +
geom_point()
library(tidytext)
trump_sentiment_nrc <- word_count %>%
inner_join(get_sentiments("nrc"))
trump_sentiment_bing <- word_count %>%
inner_join(get_sentiments("bing"))
trump_sentiment_afinn <- word_count %>%
inner_join(get_sentiments("afinn"))
ggplot(word_count[1:20, ], aes(word, n)) +
geom_point()
library(tidytext)
nrc_positive <- trump_sentiment_nrc  %>%
filter(sentiment == "positive")
nrc_positive[1:10, ] %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
bing_positive <- trump_sentiment_bing  %>%
filter(sentiment == "positive")
bing_positive %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
bing_positive <- trump_sentiment_bing  %>%
filter(sentiment == "positive")
bing_positive[1:10, ] %>%
mutate(word = reorder(word, n)) %>%
# Use aes() to put words on the x-axis and frequency on the y-axis
ggplot(aes(word, n)) +
# Make a bar chart with geom_col()
geom_col() +
coord_flip()
library(dplyr)
library(rvest)
library(stringr)
library(rebus)
library(readr)
get_first_table_no <- function(season = NA) {
link <- paste0("https://en.wikipedia.org/wiki/", season, "_NBA_season")
url <- read_html(link)
nodes <- html_nodes(url, "table")
for(table_no in 1:length(nodes)) {
ranking <- html_table(nodes[[table_no]], fill = T)
if(str_extract(names(ranking)[1], pattern = one_or_more(WRD)) == "Atlantic") break
}
return(table_no)
}
get_table <- function(season = NA, table_no = NA) {
link <- paste0("https://en.wikipedia.org/wiki/", season, "_NBA_season")
url <- read_html(link)
nodes <- html_nodes(url, "table")
ranking <- html_table(nodes[[table_no]], fill = T)
ranking[ , 1] <- str_replace(ranking[ , 1], pattern = START %R% WRD %R% or(" â€“ ", "-"), "")
ranking <- ranking %>%
mutate(
win = as.numeric(W),
lose = as.numeric(L),
game_played = win + lose,
win_rate = win / game_played,
home_performance = Home,
road_performance = Road,
division_performance = Div,
season = season,
division = str_extract(names(ranking)[1], pattern = one_or_more(WRD)),
conference = if_else(division %in% c("Atlantic", "Central", "Southeast"), "East", "West")
)
names(ranking)[1] <- "team"
ranking <- ranking %>%
select(
season,
team,
conference,
division,
game_played,
win,
lose,
win_rate,
home_performance,
road_performance,
division_performance
) %>%
arrange(desc(win_rate, win))
}
get_overall_ranking <- function(start_year = NA) {
end <- start_year + 1
start_char <- as.character(start_year)
end_char <- str_sub(as.character(end), start = -2)
season <- paste0(start_char, "-", end_char)
first_table_no <- get_first_table_no(season)
if(start_year > 2004) {
atlantic <- get_table(season, table_no = first_table_no)
central <- get_table(season, table_no = first_table_no + 1)
southeast <- get_table(season, table_no = first_table_no + 2)
northwest <- get_table(season, table_no = first_table_no + 3)
pacific <- get_table(season, table_no = first_table_no + 4)
southwest <- get_table(season, table_no = first_table_no + 5)
overall_ranking <- bind_rows(atlantic, central, southeast, northwest, pacific, southwest) %>%
arrange(desc(win_rate, win))
return(overall_ranking)
} else if(start_year < 2004){
atlantic <- get_table(season, table_no = first_table_no)
central <- get_table(season, table_no = first_table_no + 1)
midthwest <- get_table(season, table_no = first_table_no + 2)
pacific <- get_table(season, table_no = first_table_no + 3)
overall_ranking <- bind_rows(atlantic, central, midthwest, pacific) %>%
arrange(desc(win_rate, win))
}
}
ranking16_17 <- get_overall_ranking(start_year = 2016)
ranking15_16 <- get_overall_ranking(start_year = 2015)
ranking14_15 <- get_overall_ranking(start_year = 2014)
View(ranking14_15)
